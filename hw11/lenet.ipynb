{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是程序一的Python模板程序，您可以直接提交该程序而不进行任何修改（如果不介意准确率的分数），对于程序一的CUDA C/C++模板程序（加分题），请参考程序二的模板程序自行实现\n",
    "\n",
    "'''\n",
    "Package                  Version\n",
    "------------------------ ----------\n",
    "certifi                  2023.7.22\n",
    "charset-normalizer       3.2.0\n",
    "cmake                    3.27.4.1\n",
    "filelock                 3.12.4\n",
    "idna                     3.4\n",
    "Jinja2                   3.1.2\n",
    "lit                      16.0.6\n",
    "MarkupSafe               2.1.3\n",
    "mpmath                   1.3.0\n",
    "networkx                 3.1\n",
    "numpy                    1.26.0\n",
    "nvidia-cublas-cu11       11.10.3.66\n",
    "nvidia-cuda-cupti-cu11   11.7.101\n",
    "nvidia-cuda-nvrtc-cu11   11.7.99\n",
    "nvidia-cuda-runtime-cu11 11.7.99\n",
    "nvidia-cudnn-cu11        8.5.0.96\n",
    "nvidia-cufft-cu11        10.9.0.58\n",
    "nvidia-curand-cu11       10.2.10.91\n",
    "nvidia-cusolver-cu11     11.4.0.1\n",
    "nvidia-cusparse-cu11     11.7.4.91\n",
    "nvidia-nccl-cu11         2.14.3\n",
    "nvidia-nvtx-cu11         11.7.91\n",
    "Pillow                   10.0.1\n",
    "pip                      23.2.1\n",
    "requests                 2.31.0\n",
    "setuptools               68.0.0\n",
    "sympy                    1.12\n",
    "torch                    2.0.1\n",
    "torchaudio               2.0.2\n",
    "torchvision              0.15.2\n",
    "triton                   2.0.0\n",
    "typing_extensions        4.7.1\n",
    "urllib3                  2.0.4\n",
    "wheel                    0.38.4\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 输出Tensor的大小: torch.Size([1, 6, 24, 24])\n",
      "max_pool 输出Tensor的大小: torch.Size([1, 6, 12, 12])\n",
      "conv2_layer2 输出Tensor的大小: torch.Size([1, 16, 8, 8])\n",
      "max_pool 输出Tensor的大小: torch.Size([1, 16, 4, 4])\n",
      "view 输出Tensor的大小: torch.Size([1, 256])\n",
      "fc_layer2 输出Tensor的大小: torch.Size([1, 120])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.randn(1, 1, 28, 28)  # 1个样本，1个通道，28x28图像\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        input_tensor[0, 0, i, j] = i + j\n",
    "\n",
    " \n",
    "# 创建卷积层，输入通道数为1，输出通道数为6，卷积核大小为5x5\n",
    "conv_layer1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "\n",
    "# 对输入进行卷积操作\n",
    "output_tensor = conv_layer1(input_tensor)\n",
    "\n",
    "# 输出结果的大小\n",
    "print(\"conv1 输出Tensor的大小:\", output_tensor.size())\n",
    "\n",
    "pool_layer = nn.MaxPool2d(2, 2)\n",
    "output_tensor = pool_layer(output_tensor)\n",
    "print(\"max_pool 输出Tensor的大小:\", output_tensor.size())\n",
    "\n",
    "conv2_layer2 = nn.Conv2d(6, 16, 5)\n",
    "output_tensor = conv2_layer2(output_tensor)\n",
    "print(\"conv2_layer2 输出Tensor的大小:\", output_tensor.size())\n",
    "\n",
    "pool_layer = nn.MaxPool2d(2, 2)\n",
    "output_tensor = pool_layer(output_tensor)\n",
    "print(\"max_pool 输出Tensor的大小:\", output_tensor.size())\n",
    "\n",
    "\n",
    "output_tensor = output_tensor.view(-1, 16 * 4 * 4)\n",
    "print(\"view 输出Tensor的大小:\", output_tensor.size())\n",
    "\n",
    "fc = nn.Linear(16 * 4 * 4, 120)\n",
    "output_tensor = fc(output_tensor)\n",
    "print(\"fc_layer2 输出Tensor的大小:\", output_tensor.size())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.],\n",
      "          [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
      "           15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28.],\n",
      "          [ 2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15.,\n",
      "           16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29.],\n",
      "          [ 3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16.,\n",
      "           17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30.],\n",
      "          [ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17.,\n",
      "           18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31.],\n",
      "          [ 5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18.,\n",
      "           19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32.],\n",
      "          [ 6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.,\n",
      "           20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33.],\n",
      "          [ 7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20.,\n",
      "           21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34.],\n",
      "          [ 8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21.,\n",
      "           22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35.],\n",
      "          [ 9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22.,\n",
      "           23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36.],\n",
      "          [10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23.,\n",
      "           24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37.],\n",
      "          [11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.,\n",
      "           25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.],\n",
      "          [12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
      "           26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.],\n",
      "          [13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
      "           27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40.],\n",
      "          [14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
      "           28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41.],\n",
      "          [15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28.,\n",
      "           29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41., 42.],\n",
      "          [16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29.,\n",
      "           30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41., 42., 43.],\n",
      "          [17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30.,\n",
      "           31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41., 42., 43., 44.],\n",
      "          [18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31.,\n",
      "           32., 33., 34., 35., 36., 37., 38., 39., 40., 41., 42., 43., 44., 45.],\n",
      "          [19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32.,\n",
      "           33., 34., 35., 36., 37., 38., 39., 40., 41., 42., 43., 44., 45., 46.],\n",
      "          [20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33.,\n",
      "           34., 35., 36., 37., 38., 39., 40., 41., 42., 43., 44., 45., 46., 47.],\n",
      "          [21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34.,\n",
      "           35., 36., 37., 38., 39., 40., 41., 42., 43., 44., 45., 46., 47., 48.],\n",
      "          [22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35.,\n",
      "           36., 37., 38., 39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49.],\n",
      "          [23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36.,\n",
      "           37., 38., 39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50.],\n",
      "          [24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37.,\n",
      "           38., 39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51.],\n",
      "          [25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,\n",
      "           39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52.],\n",
      "          [26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.,\n",
      "           40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52., 53.],\n",
      "          [27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40.,\n",
      "           41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52., 53., 54.]]]])\n",
      "max_pool 输出Tensor的大小: torch.Size([1, 6, 12, 12])\n",
      "\n",
      "Modified Data:\n",
      "channel0:\n",
      "328.802490234375 120.04552459716797 -228.94357299804688 -522.5527954101562 -46.02833557128906 -135.62547302246094 9.289881706237793 -399.6603698730469 870.3375854492188 -149.58778381347656 \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "input_tensor = torch.randn(1, 1, 28, 28)  # 1个样本，1个通道，28x28图像\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        input_tensor[0, 0, i, j] = i + j\n",
    "\n",
    "\n",
    "# 访问Tensor的数据\n",
    "data = input_tensor.data\n",
    "\n",
    "# 打印Tensor的数据\n",
    "print(\"Original Data:\")\n",
    "print(data)\n",
    "\n",
    "# 创建卷积层，输入通道数为1，输出通道数为6，卷积核大小为5x5\n",
    "conv_layer1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "# 从文件中读取权重数据\n",
    "with open('conv1.weight_epoch400.txt', 'r') as file:\n",
    "    weights_data = [float(line.strip()) for line in file]\n",
    "\n",
    "# 将权重数据转换为PyTorch的Tensor\n",
    "weights_tensor = torch.tensor(weights_data)\n",
    "# 修改卷积层的权重\n",
    "conv_layer1.weight.data = weights_tensor.view(6, 1, 5, 5)\n",
    "\n",
    "# 打印修改后的权重\n",
    "# print(\"Modified Weights:\")\n",
    "# print(conv_layer1.weight)\n",
    "\n",
    "# 从文件中读取偏置数据\n",
    "with open('conv1.bias_epoch400.txt', 'r') as file:\n",
    "    bias_data = [float(line.strip()) for line in file]\n",
    "\n",
    "# 将偏置数据转换为PyTorch的Tensor\n",
    "bias_tensor = torch.tensor(bias_data)\n",
    "# 修改卷积层的偏置\n",
    "conv_layer1.bias.data = bias_tensor\n",
    "\n",
    "# 对输入进行卷积操作\n",
    "output_tensor = conv_layer1(input_tensor)\n",
    "\n",
    "# 输出结果的大小\n",
    "# print(\"conv1 输出Tensor的大小:\", output_tensor.size())\n",
    "relu_layer = nn.ReLU()\n",
    "output_tensor = relu_layer(output_tensor)\n",
    "pool_layer = nn.MaxPool2d(2, 2)\n",
    "output_tensor = pool_layer(output_tensor)\n",
    "print(\"max_pool 输出Tensor的大小:\", output_tensor.size())\n",
    "\n",
    "\n",
    "\n",
    "conv2_layer2 = nn.Conv2d(6, 16, 5)\n",
    "# 从文件中读取权重数据\n",
    "with open('conv2.weight_epoch400.txt', 'r') as file:\n",
    "    weights_data = [float(line.strip()) for line in file]\n",
    "\n",
    "# 将权重数据转换为PyTorch的Tensor=\n",
    "weights_tensor = torch.tensor(weights_data)\n",
    "conv2_layer2.weight.data = weights_tensor.view(16, 6, 5, 5)\n",
    "\n",
    "with open('conv2.bias_epoch400.txt', 'r') as file:\n",
    "    bias_data = [float(line.strip()) for line in file]\n",
    "\n",
    "# 将偏置数据转换为PyTorch的Tensor\n",
    "bias_tensor = torch.tensor(bias_data)\n",
    "# 修改卷积层的偏置\n",
    "conv2_layer2.bias.data = bias_tensor\n",
    "# 对输入进行卷积操作\n",
    "output_tensor = conv2_layer2(output_tensor)\n",
    "\n",
    "# 输出结果的大小\n",
    "# print(\"conv1 输出Tensor的大小:\", output_tensor.size())\n",
    "\n",
    "output_tensor = relu_layer(output_tensor)\n",
    "\n",
    "output_tensor = pool_layer(output_tensor)\n",
    "\n",
    "\n",
    "# 修改Tensor的数据（赋值）\n",
    "\n",
    "# 定义一个新的 fc1 模型\n",
    "new_fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "\n",
    "# 从文本文件中加载权重数据\n",
    "weights_data = np.loadtxt('fc1.weight_epoch400.txt')\n",
    "bias_data = np.loadtxt('fc1.bias_epoch400.txt')\n",
    "\n",
    "# 将权重和偏置数据转换为 PyTorch 的张量\n",
    "weights_tensor = torch.from_numpy(weights_data)\n",
    "bias_tensor = torch.from_numpy(bias_data)\n",
    "\n",
    "# 将权重和偏置加载到新的 fc1 模型中\n",
    "new_fc1.weight.data = weights_tensor.view(new_fc1.weight.size()).float()\n",
    "new_fc1.bias.data = bias_tensor.float()\n",
    "\n",
    "new_fc2 = nn.Linear(120, 84)\n",
    "\n",
    "# 从文本文件中加载权重数据\n",
    "weights_data = np.loadtxt('fc2.weight_epoch400.txt')\n",
    "bias_data = np.loadtxt('fc2.bias_epoch400.txt')\n",
    "\n",
    "# 将权重和偏置数据转换为 PyTorch 的张量\n",
    "weights_tensor = torch.from_numpy(weights_data)\n",
    "bias_tensor = torch.from_numpy(bias_data)\n",
    "\n",
    "# 将权重和偏置加载到新的 fc1 模型中\n",
    "new_fc2.weight.data = weights_tensor.view(new_fc2.weight.size()).float()\n",
    "new_fc2.bias.data = bias_tensor.float()\n",
    "\n",
    "new_fc3 = nn.Linear(84, 10)\n",
    "\n",
    "# 从文本文件中加载权重数据\n",
    "weights_data = np.loadtxt('fc3.weight_epoch400.txt')\n",
    "bias_data = np.loadtxt('fc3.bias_epoch400.txt')\n",
    "\n",
    "# 将权重和偏置数据转换为 PyTorch 的张量\n",
    "weights_tensor = torch.from_numpy(weights_data)\n",
    "bias_tensor = torch.from_numpy(bias_data)\n",
    "\n",
    "# 将权重和偏置加载到新的 fc1 模型中\n",
    "new_fc3.weight.data = weights_tensor.view(new_fc3.weight.size()).float()\n",
    "new_fc3.bias.data = bias_tensor.float()\n",
    "\n",
    "# 打印新的 fc1 模型\n",
    "\n",
    "output_tensor = output_tensor.view(-1, 16 * 4 * 4)\n",
    "output_tensor = new_fc1(output_tensor)\n",
    "output_tensor = relu_layer(output_tensor)\n",
    "output_tensor = new_fc2(output_tensor)\n",
    "output_tensor = relu_layer(output_tensor)\n",
    "output_tensor = new_fc3(output_tensor)\n",
    "data = output_tensor.data\n",
    "# 再次访问并打印修改后的数据\n",
    "print(\"\\nModified Data:\")\n",
    "for c in range(1):\n",
    "    print(f'channel{c}:')\n",
    "    for i in range(1):\n",
    "        \n",
    "        for j in range(10):\n",
    "            print(output_tensor[ i ,j].item(), end=' ')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义卷积层\n",
    "conv_layer1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "\n",
    "# 从文件中读取权重数据\n",
    "with open('conv1.weight_epoch400.txt', 'r') as file:\n",
    "    weights_data = [float(line.strip()) for line in file]\n",
    "\n",
    "# 将权重数据转换为PyTorch的Tensor\n",
    "weights_tensor = torch.tensor(weights_data)\n",
    "# 修改卷积层的权重\n",
    "conv_layer1.weight.data = weights_tensor.view(6, 1, 5, 5)\n",
    "\n",
    "# 打印修改后的权重\n",
    "# print(\"Modified Weights:\")\n",
    "# print(conv_layer1.weight)\n",
    "\n",
    "# 从文件中读取偏置数据\n",
    "with open('conv1.bias_epoch400.txt', 'r') as file:\n",
    "    bias_data = [float(line.strip()) for line in file]\n",
    "\n",
    "# 将偏置数据转换为PyTorch的Tensor\n",
    "bias_tensor = torch.tensor(bias_data)\n",
    "# 修改卷积层的偏置\n",
    "conv_layer1.bias.data = bias_tensor\n",
    "\n",
    "# 打印修改后的偏置\n",
    "# print(\"\\nModified Bias:\")\n",
    "# print(conv_layer1.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 定义LeNet模型\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "script_dir = os.path.dirname(__file__)  # 获取脚本所在的目录\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# 加载数据集\n",
    "trainset = torchvision.datasets.FashionMNIST(os.path.join(script_dir, '../data'), download=True, train=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(os.path.join(script_dir, '../data'), download=True, train=False, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 创建模型\n",
    "model = LeNet()\n",
    "model = model.to('cuda')\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 训练模型\n",
    "# num_epoch = 50\n",
    "# for epoch in range(num_epoch):\n",
    "#     print('epoch ', epoch)\n",
    "#     for inputs, labels in trainloader:\n",
    "#         inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data in testloader:\n",
    "#             images, labels = data\n",
    "#             images, labels = images.to('cuda'), labels.to('cuda')\n",
    "#             outputs = model(images)\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "#         print(f'epoch{epoch}, {correct/total}')\n",
    "\n",
    "# # 测试模型\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for data in testloader:\n",
    "#         images, labels = data\n",
    "#         images, labels = images.to('cuda'), labels.to('cuda')\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "        \n",
    "# print(correct/total)  \n",
    "\n",
    "# # 导出模型参数，也可以自定义导出模型参数的文件格式，这里使用了最简单的方法，但请注意，如果改动了必须保证程序二能够正常读取\n",
    "# for name, param in model.named_parameters():\n",
    "#     np.savetxt(os.path.join(script_dir, f'./{name}.txt'), param.detach().cpu().numpy().flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 定义一个新的 fc1 模型\n",
    "new_fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "\n",
    "# 打印权重矩阵的形状\n",
    "print(new_fc1.weight.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([[[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -0.9922,\n",
      "           -1.0000, -1.0000, -0.9451, -1.0000, -0.7098, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9922,\n",
      "           -0.9843, -1.0000, -0.7882, -0.3412, -0.9137, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -0.0667, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9922,\n",
      "           -1.0000, -1.0000, -0.3098,  0.1216, -0.1373, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -0.8275, -0.2706, -0.1686, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9686,\n",
      "           -1.0000, -0.5843,  0.0118, -0.0588,  0.1529,  0.3725,  0.2314,\n",
      "            0.3020,  0.0588,  0.2078,  0.3176,  0.0980, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9843, -1.0000,\n",
      "           -0.9137,  0.0745,  0.0196,  0.0039,  0.2549,  0.3804,  0.2471,\n",
      "            0.3098,  0.3961,  0.1686,  0.1843,  0.1294, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9922,\n",
      "           -1.0000, -0.9843, -0.9922, -1.0000, -0.9765, -1.0000, -1.0000,\n",
      "           -0.0980, -0.1059, -0.1686,  0.0745,  0.3176,  0.2000,  0.2235,\n",
      "            0.2941,  0.3098,  0.1216,  0.2314,  0.2392, -0.9137, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -0.9765, -1.0000, -1.0000, -0.3020,\n",
      "            0.0902, -0.2941, -0.2627,  0.2000,  0.1686,  0.0275,  0.1843,\n",
      "            0.3255,  0.3490,  0.1216,  0.2471,  0.3255, -0.6235, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9843,\n",
      "           -0.9686, -0.9922, -1.0000, -1.0000, -1.0000, -0.2314,  0.0667,\n",
      "           -0.1373, -0.1451, -0.1373,  0.2706,  0.0588,  0.1294,  0.1686,\n",
      "            0.2471,  0.3098,  0.1294,  0.2392,  0.3255, -0.0667, -1.0000],\n",
      "          [-1.0000, -1.0000, -0.9843, -0.9843, -0.9922, -0.9843, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -0.7961, -0.1529, -0.0824, -0.2235,\n",
      "           -0.1294, -0.0824,  0.0667,  0.2235,  0.0510,  0.2078,  0.2078,\n",
      "            0.2235,  0.2549,  0.1059,  0.1529,  0.2235,  0.3961, -1.0000],\n",
      "          [-0.9765, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -0.8353, -0.5843, -0.2784, -0.0824, -0.1294, -0.1922, -0.0980,\n",
      "            0.0118,  0.0510,  0.1216,  0.2078,  0.2941,  0.3333,  0.2078,\n",
      "            0.1843,  0.2078,  0.1216,  0.0824,  0.1765,  0.2941, -0.6627],\n",
      "          [-1.0000, -1.0000, -0.8196, -0.5765, -0.4902, -0.4039, -0.3333,\n",
      "           -0.0745,  0.0039, -0.0353, -0.1294, -0.1137, -0.0745, -0.0039,\n",
      "           -0.0196,  0.0902,  0.0431,  0.0667,  0.2549,  0.0980,  0.2157,\n",
      "            0.2627,  0.1294,  0.2157,  0.3490,  0.2627,  0.4824, -0.5137],\n",
      "          [-1.0000, -0.4667, -0.2627, -0.2941, -0.1294, -0.1059, -0.1294,\n",
      "           -0.1059, -0.0980, -0.0039,  0.0588,  0.0667,  0.1216, -0.0118,\n",
      "           -0.0039,  0.1843,  0.2078,  0.1216,  0.1608, -0.0196,  0.2706,\n",
      "            0.2706,  0.1294,  0.0824,  0.2000,  0.2706,  0.5373, -0.5451],\n",
      "          [-0.4510,  0.3255,  0.0118, -0.1843, -0.2314, -0.2157, -0.2627,\n",
      "           -0.2392, -0.2314, -0.2000, -0.1529, -0.1686, -0.0667, -0.0588,\n",
      "            0.0118,  0.1686,  0.2235,  0.3098,  0.4902,  0.4902,  0.5373,\n",
      "            0.5529,  0.5529,  0.4667,  0.5451,  0.4824,  0.4431, -0.7176],\n",
      "          [-0.8745, -0.0118,  0.3412,  0.4745,  0.4745,  0.4431,  0.3412,\n",
      "            0.2000,  0.0588, -0.0588, -0.0118, -0.0039,  0.1451,  0.4510,\n",
      "            0.5294,  0.6392,  0.6314,  1.0000,  0.6392,  0.3882,  0.9216,\n",
      "            0.9765,  0.9686,  0.9686,  0.9373,  0.7255,  0.6157, -0.6157],\n",
      "          [-1.0000, -1.0000, -1.0000, -0.9059, -0.4745, -0.1686,  0.2863,\n",
      "            0.4510,  0.5608,  0.6471,  0.6549,  0.6471,  0.6314,  0.4902,\n",
      "            0.1765, -0.3569, -0.9373, -1.0000, -1.0000, -1.0000,  0.3961,\n",
      "            0.6314,  0.4745,  0.3725,  0.2706,  0.2392,  0.1843, -0.9137],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]])\n",
      "Output after conv1: tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           1.0300, 0.1607, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.5505, 0.2802, 0.3326, 0.3533],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1728, 0.0000,\n",
      "           0.0447, 0.0000, 0.4576, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1088, 0.0394,\n",
      "           0.0000, 0.0361, 0.5451, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2446, 0.2419, 0.1607, 0.3013,\n",
      "           0.1277, 0.2199, 0.5823, 0.0000],\n",
      "          [0.0744, 0.0000, 0.1128, 0.0302, 0.1723, 0.1399, 0.0000, 0.1998,\n",
      "           0.0294, 0.0000, 0.1887, 0.0000],\n",
      "          [0.0000, 0.0258, 0.3393, 0.1014, 0.0509, 0.1383, 0.7325, 0.5684,\n",
      "           0.1448, 0.0000, 0.3259, 0.3614],\n",
      "          [0.3001, 0.1362, 0.0000, 0.0000, 0.1705, 0.2116, 0.5827, 0.7070,\n",
      "           1.2032, 0.0416, 0.1564, 0.0000],\n",
      "          [0.4677, 0.3999, 0.2316, 0.2994, 0.3057, 0.2378, 0.0478, 0.6485,\n",
      "           1.6057, 0.0000, 0.3480, 0.2744],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1635,\n",
      "           0.5885, 0.7150, 0.6597, 0.0542],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0826,\n",
      "           0.4949, 0.5831, 0.6021, 0.3575],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0590, 0.4425,\n",
      "           0.5929, 0.6871, 0.5234, 0.5402],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0551, 0.2673, 0.6149,\n",
      "           0.7449, 1.0826, 0.9572, 1.0261],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2197, 0.2161,\n",
      "           0.5025, 1.0156, 1.1717, 0.9856],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.1766, 0.3128, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.9214, 0.9214, 0.9214, 0.9214, 0.9214, 0.9214, 0.9214, 0.9214,\n",
      "           0.9214, 0.9214, 0.9214, 0.9214],\n",
      "          [0.9214, 0.9214, 0.9214, 0.9214, 0.9214, 0.9214, 0.9214, 0.9250,\n",
      "           0.9334, 0.9364, 0.9940, 1.0694],\n",
      "          [0.9214, 0.9214, 0.9214, 0.9214, 0.9243, 0.9264, 1.1653, 2.1832,\n",
      "           2.1919, 0.9763, 1.4144, 2.2236],\n",
      "          [0.9214, 0.9214, 0.9214, 0.9214, 0.9305, 1.1759, 1.9106, 2.9049,\n",
      "           4.1803, 3.8656, 3.7320, 2.8420],\n",
      "          [0.9226, 0.9272, 0.9279, 0.9363, 1.0384, 1.6395, 1.7963, 2.0324,\n",
      "           4.5398, 4.8895, 4.7542, 3.0268],\n",
      "          [0.9382, 0.9350, 0.9476, 1.0297, 1.8422, 2.3385, 1.5183, 0.1867,\n",
      "           0.0000, 0.0000, 0.3181, 1.9922],\n",
      "          [1.2992, 1.5653, 1.8901, 2.7229, 2.8064, 1.9454, 1.0573, 0.3778,\n",
      "           0.4185, 0.0434, 0.0880, 1.0871],\n",
      "          [2.9154, 3.2524, 3.1754, 3.1880, 2.4254, 1.1474, 0.6486, 0.5330,\n",
      "           0.3609, 0.5492, 0.6808, 0.5780],\n",
      "          [3.4100, 3.1646, 2.4027, 1.1432, 0.8165, 0.9699, 0.8581, 0.8020,\n",
      "           0.9964, 1.6721, 1.7172, 1.0858],\n",
      "          [0.0000, 0.1055, 0.4903, 0.4345, 0.1742, 0.0735, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6066, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7042,\n",
      "           0.1804, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9214, 0.9214, 0.9214, 0.9214, 0.9214, 0.9214, 0.9214, 0.9214,\n",
      "           0.9214, 0.9214, 0.9214, 0.9214]],\n",
      "\n",
      "         [[0.5528, 0.5528, 0.5528, 0.5528, 0.5528, 0.5528, 0.5528, 0.5528,\n",
      "           0.5528, 0.5528, 0.5528, 0.5528],\n",
      "          [0.5528, 0.5528, 0.5528, 0.5528, 0.5528, 0.5528, 0.5528, 0.5528,\n",
      "           0.5538, 0.5689, 0.5528, 0.5842],\n",
      "          [0.5528, 0.5528, 0.5528, 0.5528, 0.5528, 0.5502, 0.4590, 1.2554,\n",
      "           1.8452, 0.5673, 0.5305, 1.4815],\n",
      "          [0.5528, 0.5528, 0.5528, 0.5528, 0.5528, 0.5337, 0.0000, 1.0515,\n",
      "           1.7553, 0.8757, 0.2115, 3.4882],\n",
      "          [0.5528, 0.5546, 0.5506, 0.5526, 0.5446, 0.0681, 0.0000, 0.2404,\n",
      "           1.1782, 0.8247, 0.3464, 4.7655],\n",
      "          [0.5549, 0.5451, 0.5659, 0.5596, 0.1872, 0.0000, 0.0000, 0.0000,\n",
      "           0.1188, 0.6378, 0.7354, 4.9962],\n",
      "          [0.5539, 0.5500, 0.3196, 0.0000, 0.0000, 0.0000, 0.0592, 0.0000,\n",
      "           0.2834, 0.5829, 0.7007, 4.0233],\n",
      "          [0.3839, 0.3283, 0.0797, 0.0000, 0.0000, 0.2097, 0.0208, 0.1379,\n",
      "           0.2315, 0.7402, 0.6031, 3.1451],\n",
      "          [0.3969, 0.4835, 0.3165, 0.3938, 0.1937, 0.2573, 0.7013, 0.6107,\n",
      "           0.2365, 0.6116, 0.6343, 3.6794],\n",
      "          [0.0217, 0.0924, 0.4634, 0.4333, 0.2865, 0.7967, 1.2449, 0.7253,\n",
      "           0.0000, 0.3859, 0.7906, 3.2203],\n",
      "          [0.2013, 0.0000, 0.3328, 0.3896, 0.3880, 1.0020, 1.3978, 1.0218,\n",
      "           0.0000, 0.1100, 0.5480, 2.0013],\n",
      "          [0.5528, 0.5528, 0.5528, 0.5528, 0.5528, 0.5528, 0.5528, 0.5528,\n",
      "           0.5528, 0.5528, 0.5528, 0.5528]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.3861, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1299,\n",
      "           0.3569, 0.7612, 0.7113, 0.3347],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.5958, 0.6853, 0.6430, 0.4590],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3127,\n",
      "           0.7709, 0.9803, 0.8772, 1.0309],\n",
      "          [0.0000, 0.0000, 0.0000, 0.4093, 0.7195, 0.9758, 0.8772, 1.2958,\n",
      "           1.3864, 1.6341, 1.7563, 1.6382],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[7.6079, 7.6079, 7.6079, 7.6079, 7.6079, 7.6079, 7.6079, 7.6079,\n",
      "           7.6079, 7.6079, 7.6079, 7.6079],\n",
      "          [7.6079, 7.6079, 7.6079, 7.6079, 7.6079, 7.6079, 7.6079, 7.6079,\n",
      "           7.6079, 7.6079, 7.6079, 7.6079],\n",
      "          [7.6079, 7.6079, 7.6079, 7.6079, 7.6079, 7.5965, 7.4966, 7.2567,\n",
      "           7.7539, 7.7016, 7.5707, 7.1426],\n",
      "          [7.6079, 7.6079, 7.6079, 7.6079, 7.6079, 7.5718, 6.3214, 4.4963,\n",
      "           5.8804, 6.0712, 5.3117, 6.2851],\n",
      "          [7.6079, 7.6040, 7.5969, 7.5980, 7.5869, 7.0725, 3.6379, 0.6608,\n",
      "           1.0580, 1.6347, 1.3304, 5.3876],\n",
      "          [7.6029, 7.5932, 7.5785, 7.5762, 7.2009, 4.5318, 1.8512, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 3.6848],\n",
      "          [7.5859, 7.5806, 7.2778, 6.4442, 4.6541, 2.0485, 0.8938, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 1.7780],\n",
      "          [5.7814, 5.3679, 4.5566, 3.3815, 1.7846, 0.7717, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0285],\n",
      "          [2.1044, 1.8595, 1.4534, 0.8837, 0.2540, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [3.7673, 2.4829, 1.8579, 1.8172, 1.6744, 1.6725, 2.6488, 3.0141,\n",
      "           2.0637, 0.0000, 0.0000, 2.2368],\n",
      "          [7.4197, 6.8496, 6.1835, 5.7810, 5.7071, 6.1242, 6.9191, 7.4694,\n",
      "           7.1472, 6.3756, 5.9765, 6.4883],\n",
      "          [7.6079, 7.6079, 7.6079, 7.6079, 7.6079, 7.6079, 7.6079, 7.6079,\n",
      "           7.6079, 7.6079, 7.6079, 7.6079]]]])\n",
      "Output after conv2: tensor([[[[ 0.0000,  0.0000,  0.6235,  2.0303],\n",
      "          [ 0.0000,  0.9854,  2.7867,  3.7743],\n",
      "          [ 1.0529,  3.6811,  4.2098,  3.9641],\n",
      "          [ 3.4492,  2.7769,  0.9107,  0.7745]],\n",
      "\n",
      "         [[ 0.4921,  2.0835,  2.9017,  1.6823],\n",
      "          [ 1.5882,  1.8568,  2.8093,  3.0888],\n",
      "          [ 1.4275,  0.6986,  0.0000,  1.5903],\n",
      "          [ 0.0000,  0.0000,  0.4280,  0.9856]],\n",
      "\n",
      "         [[ 0.6918,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.1968],\n",
      "          [ 6.7422,  9.0190,  9.2136,  9.2423]],\n",
      "\n",
      "         [[ 2.7034,  1.7377,  0.0000,  0.0000],\n",
      "          [ 1.5809,  0.0000,  1.5222,  0.1554],\n",
      "          [ 0.0000,  1.9382,  3.4209,  1.3109],\n",
      "          [ 4.1962,  5.0924,  5.0704,  3.2743]],\n",
      "\n",
      "         [[ 8.2872,  7.3467,  5.8449,  5.3015],\n",
      "          [ 7.2118,  5.3638,  4.3691,  3.5582],\n",
      "          [ 5.2244,  3.7241,  1.5795,  0.1094],\n",
      "          [ 4.9450,  3.5811,  1.8906,  0.5189]],\n",
      "\n",
      "         [[ 0.0000,  0.7768,  4.9816,  9.5312],\n",
      "          [ 1.5287,  4.1962,  7.2937, 11.8161],\n",
      "          [ 7.1778,  6.3329,  3.3437,  0.6468],\n",
      "          [ 4.8745,  3.1349,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 5.4034,  4.5300,  0.0000,  0.0000],\n",
      "          [ 3.7164,  0.3779,  0.0000,  0.0000],\n",
      "          [ 0.0000,  1.0168,  4.6294,  3.6886],\n",
      "          [ 8.1082,  9.8161, 11.4701, 10.8992]],\n",
      "\n",
      "         [[ 3.2733,  2.9089,  3.2862,  2.4847],\n",
      "          [ 2.8955,  2.9181,  4.7462,  1.4692],\n",
      "          [ 2.6225,  2.0839,  1.6589,  0.5326],\n",
      "          [ 1.3949,  0.1221,  0.5243,  1.7496]],\n",
      "\n",
      "         [[ 0.5813,  0.5096,  0.8114,  1.9430],\n",
      "          [ 0.6750,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.3251,  1.4965],\n",
      "          [ 0.3585,  1.8621,  2.5374,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  1.0854,  3.3526,  3.5589],\n",
      "          [ 0.7265,  0.4914,  2.8085,  3.8153],\n",
      "          [ 1.6352,  1.1035,  2.9829,  3.1512],\n",
      "          [ 1.1137,  1.3044,  1.6276,  2.1404]],\n",
      "\n",
      "         [[ 1.0101,  0.9113,  0.0000,  0.0000],\n",
      "          [ 0.5301,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  1.5738,  1.2631],\n",
      "          [ 4.8573,  6.3585, 10.4441,  9.6102]],\n",
      "\n",
      "         [[ 8.1917,  8.5391,  8.0912,  8.5968],\n",
      "          [ 8.8220,  8.5014,  7.1195,  8.0024],\n",
      "          [ 8.7411,  7.4942,  3.4786,  6.0003],\n",
      "          [ 6.9802,  4.7167,  0.7617,  0.0000]],\n",
      "\n",
      "         [[ 0.9062,  1.5476,  4.5670,  6.0728],\n",
      "          [ 1.6680,  0.6398,  3.6286,  6.3909],\n",
      "          [ 2.9970,  0.8199,  0.2816,  2.3680],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.3391,  0.2514],\n",
      "          [ 0.0000,  0.0735,  2.4465,  3.2496],\n",
      "          [ 0.5567,  1.2849,  2.6816,  5.0532],\n",
      "          [ 1.8903,  1.8717,  1.3594,  2.7514]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  3.7753],\n",
      "          [ 0.0000,  0.6639,  0.7401,  3.0022],\n",
      "          [ 2.5860,  2.9725,  1.8517,  1.0544],\n",
      "          [ 1.4700,  1.5395,  0.3621,  0.0000]],\n",
      "\n",
      "         [[ 1.7158,  6.2754,  7.4669,  5.6101],\n",
      "          [ 4.7511,  6.3016,  8.6563,  8.4282],\n",
      "          [ 6.1882,  4.7107,  1.9941,  1.7786],\n",
      "          [ 6.2478,  3.1897,  3.5567,  4.0235]]]])\n",
      "Output after view: tensor([[ 0.0000,  0.0000,  0.6235,  2.0303,  0.0000,  0.9854,  2.7867,  3.7743,\n",
      "          1.0529,  3.6811,  4.2098,  3.9641,  3.4492,  2.7769,  0.9107,  0.7745,\n",
      "          0.4921,  2.0835,  2.9017,  1.6823,  1.5882,  1.8568,  2.8093,  3.0888,\n",
      "          1.4275,  0.6986,  0.0000,  1.5903,  0.0000,  0.0000,  0.4280,  0.9856,\n",
      "          0.6918,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.1968,  6.7422,  9.0190,  9.2136,  9.2423,\n",
      "          2.7034,  1.7377,  0.0000,  0.0000,  1.5809,  0.0000,  1.5222,  0.1554,\n",
      "          0.0000,  1.9382,  3.4209,  1.3109,  4.1962,  5.0924,  5.0704,  3.2743,\n",
      "          8.2872,  7.3467,  5.8449,  5.3015,  7.2118,  5.3638,  4.3691,  3.5582,\n",
      "          5.2244,  3.7241,  1.5795,  0.1094,  4.9450,  3.5811,  1.8906,  0.5189,\n",
      "          0.0000,  0.7768,  4.9816,  9.5312,  1.5287,  4.1962,  7.2937, 11.8161,\n",
      "          7.1778,  6.3329,  3.3437,  0.6468,  4.8745,  3.1349,  0.0000,  0.0000,\n",
      "          5.4034,  4.5300,  0.0000,  0.0000,  3.7164,  0.3779,  0.0000,  0.0000,\n",
      "          0.0000,  1.0168,  4.6294,  3.6886,  8.1082,  9.8161, 11.4701, 10.8992,\n",
      "          3.2733,  2.9089,  3.2862,  2.4847,  2.8955,  2.9181,  4.7462,  1.4692,\n",
      "          2.6225,  2.0839,  1.6589,  0.5326,  1.3949,  0.1221,  0.5243,  1.7496,\n",
      "          0.5813,  0.5096,  0.8114,  1.9430,  0.6750,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.3251,  1.4965,  0.3585,  1.8621,  2.5374,  0.0000,\n",
      "          0.0000,  1.0854,  3.3526,  3.5589,  0.7265,  0.4914,  2.8085,  3.8153,\n",
      "          1.6352,  1.1035,  2.9829,  3.1512,  1.1137,  1.3044,  1.6276,  2.1404,\n",
      "          1.0101,  0.9113,  0.0000,  0.0000,  0.5301,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  1.5738,  1.2631,  4.8573,  6.3585, 10.4441,  9.6102,\n",
      "          8.1917,  8.5391,  8.0912,  8.5968,  8.8220,  8.5014,  7.1195,  8.0024,\n",
      "          8.7411,  7.4942,  3.4786,  6.0003,  6.9802,  4.7167,  0.7617,  0.0000,\n",
      "          0.9062,  1.5476,  4.5670,  6.0728,  1.6680,  0.6398,  3.6286,  6.3909,\n",
      "          2.9970,  0.8199,  0.2816,  2.3680,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.3391,  0.2514,  0.0000,  0.0735,  2.4465,  3.2496,\n",
      "          0.5567,  1.2849,  2.6816,  5.0532,  1.8903,  1.8717,  1.3594,  2.7514,\n",
      "          0.0000,  0.0000,  0.0000,  3.7753,  0.0000,  0.6639,  0.7401,  3.0022,\n",
      "          2.5860,  2.9725,  1.8517,  1.0544,  1.4700,  1.5395,  0.3621,  0.0000,\n",
      "          1.7158,  6.2754,  7.4669,  5.6101,  4.7511,  6.3016,  8.6563,  8.4282,\n",
      "          6.1882,  4.7107,  1.9941,  1.7786,  6.2478,  3.1897,  3.5567,  4.0235]])\n",
      "Output after fc1: tensor([[0.0000, 0.9275, 0.0000, 8.2658, 0.0000, 1.2074, 4.3601, 0.0000, 0.6531,\n",
      "         0.0000, 0.0000, 2.8630, 5.3305, 0.0000, 1.8660, 0.0000, 0.0000, 1.8782,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 5.2011, 4.6731, 5.2725, 2.6974,\n",
      "         0.0000, 1.2775, 0.1467, 0.4869, 0.5346, 1.7513, 1.6824, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.5659, 0.7512, 0.2490, 0.0000, 6.7290, 4.3165,\n",
      "         1.5341, 0.9525, 0.1568, 1.9582, 0.0000, 0.0000, 0.0000, 1.1695, 0.0000,\n",
      "         2.4506, 0.0000, 0.0000, 0.0000, 0.0000, 2.1793, 0.0000, 6.1364, 1.2015,\n",
      "         0.0000, 4.4500, 3.4768, 6.5326, 0.8943, 0.0000, 7.4487, 0.0000, 0.0000,\n",
      "         3.9066, 0.0000, 0.0000, 1.6901, 0.0000, 0.0000, 4.4758, 0.0000, 0.0000,\n",
      "         0.8879, 2.0917, 0.0000, 9.3879, 0.0000, 0.0000, 0.7036, 1.5970, 0.0000,\n",
      "         2.5362, 0.0000, 1.5190, 0.0000, 4.6785, 4.8383, 0.9025, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 3.0040, 0.2218, 0.0000, 0.0000, 1.9253, 3.4696, 1.4499,\n",
      "         2.6412, 0.0000, 9.6450, 4.5651, 0.0000, 0.0000, 0.4718, 4.1678, 0.0000,\n",
      "         0.0000, 0.3581, 4.1685]])\n",
      "Output after fc2: tensor([[0.0000, 0.0000, 3.1008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         8.6491, 1.2267, 0.0000, 2.8018, 0.0000, 0.4712, 0.0000, 7.6556, 4.3041,\n",
      "         0.0000, 0.0000, 2.0452, 0.0000, 0.0000, 2.6343, 6.7059, 4.7965, 0.0000,\n",
      "         7.7666, 1.5638, 0.0000, 0.0000, 2.8280, 5.5690, 7.0165, 0.0000, 0.8592,\n",
      "         0.0000, 0.0000, 0.0000, 3.9778, 0.0000, 1.6737, 0.0000, 0.0000, 1.6374,\n",
      "         5.2652, 1.5572, 0.0000, 0.0000, 5.2952, 0.0000, 2.5505, 0.0000, 6.8093,\n",
      "         1.0213, 0.8748, 3.3838, 0.0000, 0.9009, 1.3889, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.3609, 0.6384, 1.5512, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.1241, 0.4111, 3.3248, 0.0000, 0.0000, 0.0000, 0.0000, 1.7796,\n",
      "         0.0000, 1.0915, 0.0000]])\n",
      "Final output: tensor([[-0.1683, -8.9737, -7.3749, -6.9867, -4.6275,  9.1723, -4.9007,  8.1733,\n",
      "         -1.8484, 13.6331]])\n",
      "real : tensor([9]), predict tensor([9]) \n",
      "1\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# 定义你的 LeNet 模型\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        print(\"Output after conv1:\", x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        print(\"Output after conv2:\", x)\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        print(\"Output after view:\", x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        print(\"Output after fc1:\", x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        print(\"Output after fc2:\", x)\n",
    "        x = self.fc3(x)\n",
    "        print(\"Final output:\", x)\n",
    "        return x\n",
    "\n",
    "# 加载权重和偏置\n",
    "def load_weights_and_biases(model, dir):\n",
    "    # 读取权重和偏置数据\n",
    "    conv1_weight = np.loadtxt(dir + \"/conv1.weight.txt\").reshape(model.conv1.weight.shape)\n",
    "    conv1_bias = np.loadtxt(dir + \"/conv1.bias.txt\").reshape(model.conv1.bias.shape)\n",
    "    conv2_weight = np.loadtxt(dir + \"/conv2.weight.txt\").reshape(model.conv2.weight.shape)\n",
    "    conv2_bias = np.loadtxt(dir + \"/conv2.bias.txt\").reshape(model.conv2.bias.shape)\n",
    "    fc1_weight = np.loadtxt(dir + \"/fc1.weight.txt\").reshape(model.fc1.weight.shape)\n",
    "    fc1_bias = np.loadtxt(dir + \"/fc1.bias.txt\").reshape(model.fc1.bias.shape)\n",
    "    fc2_weight = np.loadtxt(dir + \"/fc2.weight.txt\").reshape(model.fc2.weight.shape)\n",
    "    fc2_bias = np.loadtxt(dir + \"/fc2.bias.txt\").reshape(model.fc2.bias.shape)\n",
    "    fc3_weight = np.loadtxt(dir + \"/fc3.weight.txt\").reshape(model.fc3.weight.shape)\n",
    "    fc3_bias = np.loadtxt(dir + \"/fc3.bias.txt\").reshape(model.fc3.bias.shape)\n",
    "\n",
    "    # 将权重和偏置加载到模型中\n",
    "    model.conv1.weight.data = torch.from_numpy(conv1_weight).float()\n",
    "    model.conv1.bias.data = torch.from_numpy(conv1_bias).float()\n",
    "    model.conv2.weight.data = torch.from_numpy(conv2_weight).float()\n",
    "    model.conv2.bias.data = torch.from_numpy(conv2_bias).float()\n",
    "    model.fc1.weight.data = torch.from_numpy(fc1_weight).float()\n",
    "    model.fc1.bias.data = torch.from_numpy(fc1_bias).float()\n",
    "    model.fc2.weight.data = torch.from_numpy(fc2_weight).float()\n",
    "    model.fc2.bias.data = torch.from_numpy(fc2_bias).float()\n",
    "    model.fc3.weight.data = torch.from_numpy(fc3_weight).float()\n",
    "    model.fc3.bias.data = torch.from_numpy(fc3_bias).float()\n",
    "\n",
    "# 使用例子\n",
    "model = LeNet()\n",
    "load_weights_and_biases(model, \"/share/home/wanghongyu/Workspace/Courses/UCAS-GPU/hw11\")\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# 加载数据集\n",
    "trainset = torchvision.datasets.FashionMNIST(os.path.join('/share/home/wanghongyu/Workspace/Courses/UCAS-GPU/data'), download=True, train=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(os.path.join('/share/home/wanghongyu/Workspace/Courses/UCAS-GPU/data'), download=True, train=False, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n",
    "\n",
    "# 执行推理等操作\n",
    "# ...\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        print(f'input: {images}')\n",
    "        outputs = model(images)\n",
    "        # print(f'output[{total}]: {outputs}')\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print(f'real : {labels}, predict {predicted} ')\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        break\n",
    "    \n",
    "print(total)\n",
    "print(correct/total)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.],\n",
      "          [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
      "           15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28.],\n",
      "          [ 2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15.,\n",
      "           16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29.],\n",
      "          [ 3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16.,\n",
      "           17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30.],\n",
      "          [ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17.,\n",
      "           18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31.],\n",
      "          [ 5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18.,\n",
      "           19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32.],\n",
      "          [ 6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.,\n",
      "           20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33.],\n",
      "          [ 7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20.,\n",
      "           21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34.],\n",
      "          [ 8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21.,\n",
      "           22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35.],\n",
      "          [ 9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22.,\n",
      "           23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36.],\n",
      "          [10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23.,\n",
      "           24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37.],\n",
      "          [11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.,\n",
      "           25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.],\n",
      "          [12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
      "           26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.],\n",
      "          [13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
      "           27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40.],\n",
      "          [14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
      "           28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41.],\n",
      "          [15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28.,\n",
      "           29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41., 42.],\n",
      "          [16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29.,\n",
      "           30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41., 42., 43.],\n",
      "          [17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30.,\n",
      "           31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41., 42., 43., 44.],\n",
      "          [18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31.,\n",
      "           32., 33., 34., 35., 36., 37., 38., 39., 40., 41., 42., 43., 44., 45.],\n",
      "          [19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32.,\n",
      "           33., 34., 35., 36., 37., 38., 39., 40., 41., 42., 43., 44., 45., 46.],\n",
      "          [20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33.,\n",
      "           34., 35., 36., 37., 38., 39., 40., 41., 42., 43., 44., 45., 46., 47.],\n",
      "          [21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34.,\n",
      "           35., 36., 37., 38., 39., 40., 41., 42., 43., 44., 45., 46., 47., 48.],\n",
      "          [22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35.,\n",
      "           36., 37., 38., 39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49.],\n",
      "          [23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36.,\n",
      "           37., 38., 39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50.],\n",
      "          [24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37.,\n",
      "           38., 39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51.],\n",
      "          [25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,\n",
      "           39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52.],\n",
      "          [26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.,\n",
      "           40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52., 53.],\n",
      "          [27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40.,\n",
      "           41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52., 53., 54.]]]])\n",
      "Output after conv1: tensor([[[[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "         [[ 17.5293,  24.0968,  30.6642,  37.2316,  43.7990,  50.3664,  56.9338,\n",
      "            63.5012,  70.0686,  76.6360,  83.2034,  89.7708],\n",
      "          [ 24.0968,  30.6642,  37.2316,  43.7990,  50.3664,  56.9338,  63.5012,\n",
      "            70.0686,  76.6360,  83.2034,  89.7708,  96.3382],\n",
      "          [ 30.6642,  37.2316,  43.7990,  50.3664,  56.9338,  63.5012,  70.0686,\n",
      "            76.6360,  83.2034,  89.7708,  96.3382, 102.9056],\n",
      "          [ 37.2316,  43.7990,  50.3664,  56.9338,  63.5012,  70.0686,  76.6360,\n",
      "            83.2034,  89.7708,  96.3382, 102.9056, 109.4730],\n",
      "          [ 43.7990,  50.3664,  56.9338,  63.5012,  70.0686,  76.6360,  83.2034,\n",
      "            89.7708,  96.3382, 102.9056, 109.4730, 116.0404],\n",
      "          [ 50.3664,  56.9338,  63.5012,  70.0686,  76.6360,  83.2034,  89.7708,\n",
      "            96.3382, 102.9056, 109.4730, 116.0404, 122.6078],\n",
      "          [ 56.9338,  63.5012,  70.0686,  76.6360,  83.2034,  89.7708,  96.3382,\n",
      "           102.9056, 109.4730, 116.0404, 122.6078, 129.1752],\n",
      "          [ 63.5012,  70.0686,  76.6360,  83.2034,  89.7708,  96.3382, 102.9056,\n",
      "           109.4730, 116.0404, 122.6078, 129.1752, 135.7426],\n",
      "          [ 70.0686,  76.6360,  83.2034,  89.7708,  96.3382, 102.9056, 109.4730,\n",
      "           116.0404, 122.6078, 129.1752, 135.7426, 142.3101],\n",
      "          [ 76.6360,  83.2034,  89.7708,  96.3382, 102.9056, 109.4730, 116.0404,\n",
      "           122.6078, 129.1752, 135.7426, 142.3101, 148.8775],\n",
      "          [ 83.2034,  89.7708,  96.3382, 102.9056, 109.4730, 116.0404, 122.6078,\n",
      "           129.1752, 135.7426, 142.3101, 148.8775, 155.4449],\n",
      "          [ 89.7708,  96.3382, 102.9056, 109.4730, 116.0404, 122.6078, 129.1752,\n",
      "           135.7426, 142.3101, 148.8775, 155.4449, 162.0123]],\n",
      "\n",
      "         [[  4.3902,   3.1065,   1.8228,   0.5391,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  3.1065,   1.8228,   0.5391,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  1.8228,   0.5391,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.5391,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "         [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "         [[ 21.0194,  28.1304,  35.2414,  42.3524,  49.4634,  56.5744,  63.6854,\n",
      "            70.7964,  77.9074,  85.0184,  92.1294,  99.2404],\n",
      "          [ 28.1304,  35.2414,  42.3524,  49.4634,  56.5744,  63.6854,  70.7964,\n",
      "            77.9074,  85.0184,  92.1294,  99.2404, 106.3514],\n",
      "          [ 35.2414,  42.3524,  49.4634,  56.5744,  63.6854,  70.7964,  77.9074,\n",
      "            85.0184,  92.1294,  99.2404, 106.3514, 113.4624],\n",
      "          [ 42.3524,  49.4634,  56.5744,  63.6854,  70.7964,  77.9074,  85.0184,\n",
      "            92.1294,  99.2404, 106.3514, 113.4624, 120.5734],\n",
      "          [ 49.4634,  56.5744,  63.6854,  70.7964,  77.9074,  85.0184,  92.1294,\n",
      "            99.2404, 106.3514, 113.4624, 120.5734, 127.6844],\n",
      "          [ 56.5744,  63.6854,  70.7964,  77.9074,  85.0184,  92.1294,  99.2404,\n",
      "           106.3514, 113.4624, 120.5734, 127.6844, 134.7954],\n",
      "          [ 63.6854,  70.7964,  77.9074,  85.0184,  92.1294,  99.2404, 106.3514,\n",
      "           113.4624, 120.5734, 127.6844, 134.7954, 141.9064],\n",
      "          [ 70.7964,  77.9074,  85.0184,  92.1294,  99.2404, 106.3514, 113.4624,\n",
      "           120.5734, 127.6844, 134.7954, 141.9064, 149.0174],\n",
      "          [ 77.9074,  85.0184,  92.1294,  99.2404, 106.3514, 113.4624, 120.5734,\n",
      "           127.6844, 134.7954, 141.9064, 149.0174, 156.1284],\n",
      "          [ 85.0184,  92.1294,  99.2404, 106.3514, 113.4624, 120.5734, 127.6844,\n",
      "           134.7954, 141.9064, 149.0174, 156.1284, 163.2394],\n",
      "          [ 92.1294,  99.2404, 106.3514, 113.4624, 120.5734, 127.6844, 134.7954,\n",
      "           141.9064, 149.0174, 156.1284, 163.2394, 170.3504],\n",
      "          [ 99.2404, 106.3514, 113.4624, 120.5734, 127.6844, 134.7954, 141.9064,\n",
      "           149.0174, 156.1284, 163.2394, 170.3504, 177.4614]],\n",
      "\n",
      "         [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]]],\n",
      "       grad_fn=<MaxPool2DWithIndicesBackward0>)\n",
      "Output after conv2: tensor([[[[2.3926e+01, 2.5825e+01, 2.7804e+01, 2.9783e+01],\n",
      "          [2.5825e+01, 2.7804e+01, 2.9783e+01, 3.1762e+01],\n",
      "          [2.7804e+01, 2.9783e+01, 3.1762e+01, 3.3740e+01],\n",
      "          [2.9783e+01, 3.1762e+01, 3.3740e+01, 3.5719e+01]],\n",
      "\n",
      "         [[0.0000e+00, 1.8035e+00, 3.9909e+00, 6.1782e+00],\n",
      "          [1.8035e+00, 3.9909e+00, 6.1782e+00, 8.3656e+00],\n",
      "          [3.9909e+00, 6.1782e+00, 8.3656e+00, 1.0553e+01],\n",
      "          [6.1782e+00, 8.3656e+00, 1.0553e+01, 1.2740e+01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[1.0444e+02, 1.2579e+02, 1.4748e+02, 1.6918e+02],\n",
      "          [1.2579e+02, 1.4748e+02, 1.6918e+02, 1.9088e+02],\n",
      "          [1.4748e+02, 1.6918e+02, 1.9088e+02, 2.1257e+02],\n",
      "          [1.6918e+02, 1.9088e+02, 2.1257e+02, 2.3427e+02]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[5.6700e+01, 7.1449e+01, 8.6413e+01, 1.0138e+02],\n",
      "          [7.1449e+01, 8.6413e+01, 1.0138e+02, 1.1634e+02],\n",
      "          [8.6413e+01, 1.0138e+02, 1.1634e+02, 1.3130e+02],\n",
      "          [1.0138e+02, 1.1634e+02, 1.3130e+02, 1.4627e+02]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[6.3284e+00, 8.3219e+00, 1.0296e+01, 1.2270e+01],\n",
      "          [8.3219e+00, 1.0296e+01, 1.2270e+01, 1.4245e+01],\n",
      "          [1.0296e+01, 1.2270e+01, 1.4245e+01, 1.6219e+01],\n",
      "          [1.2270e+01, 1.4245e+01, 1.6219e+01, 1.8193e+01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[5.7814e+01, 6.8821e+01, 7.9832e+01, 9.0844e+01],\n",
      "          [6.8821e+01, 7.9832e+01, 9.0844e+01, 1.0185e+02],\n",
      "          [7.9832e+01, 9.0844e+01, 1.0185e+02, 1.1287e+02],\n",
      "          [9.0844e+01, 1.0185e+02, 1.1287e+02, 1.2388e+02]],\n",
      "\n",
      "         [[1.2981e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[4.3054e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]],\n",
      "       grad_fn=<MaxPool2DWithIndicesBackward0>)\n",
      "Output after view: tensor([[2.3926e+01, 2.5825e+01, 2.7804e+01, 2.9783e+01, 2.5825e+01, 2.7804e+01,\n",
      "         2.9783e+01, 3.1762e+01, 2.7804e+01, 2.9783e+01, 3.1762e+01, 3.3740e+01,\n",
      "         2.9783e+01, 3.1762e+01, 3.3740e+01, 3.5719e+01, 0.0000e+00, 1.8035e+00,\n",
      "         3.9909e+00, 6.1782e+00, 1.8035e+00, 3.9909e+00, 6.1782e+00, 8.3656e+00,\n",
      "         3.9909e+00, 6.1782e+00, 8.3656e+00, 1.0553e+01, 6.1782e+00, 8.3656e+00,\n",
      "         1.0553e+01, 1.2740e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0444e+02, 1.2579e+02, 1.4748e+02, 1.6918e+02, 1.2579e+02, 1.4748e+02,\n",
      "         1.6918e+02, 1.9088e+02, 1.4748e+02, 1.6918e+02, 1.9088e+02, 2.1257e+02,\n",
      "         1.6918e+02, 1.9088e+02, 2.1257e+02, 2.3427e+02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.6700e+01, 7.1449e+01, 8.6413e+01, 1.0138e+02,\n",
      "         7.1449e+01, 8.6413e+01, 1.0138e+02, 1.1634e+02, 8.6413e+01, 1.0138e+02,\n",
      "         1.1634e+02, 1.3130e+02, 1.0138e+02, 1.1634e+02, 1.3130e+02, 1.4627e+02,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.3284e+00, 8.3219e+00, 1.0296e+01, 1.2270e+01,\n",
      "         8.3219e+00, 1.0296e+01, 1.2270e+01, 1.4245e+01, 1.0296e+01, 1.2270e+01,\n",
      "         1.4245e+01, 1.6219e+01, 1.2270e+01, 1.4245e+01, 1.6219e+01, 1.8193e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.7814e+01, 6.8821e+01, 7.9832e+01, 9.0844e+01,\n",
      "         6.8821e+01, 7.9832e+01, 9.0844e+01, 1.0185e+02, 7.9832e+01, 9.0844e+01,\n",
      "         1.0185e+02, 1.1287e+02, 9.0844e+01, 1.0185e+02, 1.1287e+02, 1.2388e+02,\n",
      "         1.2981e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3054e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Output after fc1: tensor([[0.0000e+00, 4.2989e+01, 0.0000e+00, 1.4293e+01, 0.0000e+00, 5.4790e+01,\n",
      "         0.0000e+00, 5.9747e+01, 1.8867e+01, 0.0000e+00, 7.9820e+01, 0.0000e+00,\n",
      "         0.0000e+00, 1.4375e+02, 1.1190e-01, 0.0000e+00, 9.5802e+00, 1.8523e+01,\n",
      "         0.0000e+00, 1.2074e+01, 6.2118e+00, 0.0000e+00, 0.0000e+00, 8.3862e+00,\n",
      "         0.0000e+00, 6.1550e+01, 7.6985e+00, 0.0000e+00, 6.6093e+01, 6.7516e+01,\n",
      "         1.2508e+01, 9.8285e+00, 0.0000e+00, 0.0000e+00, 1.7926e+01, 7.6337e+01,\n",
      "         1.0228e+01, 0.0000e+00, 9.9737e+01, 6.6373e+01, 3.2227e+01, 0.0000e+00,\n",
      "         3.4409e+01, 1.5521e+01, 6.8297e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.7473e+01, 2.6130e-01, 0.0000e+00, 0.0000e+00, 1.3410e+01, 0.0000e+00,\n",
      "         6.2381e-01, 8.3470e+01, 0.0000e+00, 2.4997e+01, 0.0000e+00, 4.1173e+01,\n",
      "         0.0000e+00, 4.4712e+00, 3.5493e+00, 3.9368e+01, 0.0000e+00, 6.7839e+01,\n",
      "         6.2043e+01, 1.4406e+01, 0.0000e+00, 0.0000e+00, 3.9869e+01, 0.0000e+00,\n",
      "         2.4843e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.4365e+01, 0.0000e+00, 0.0000e+00, 5.7795e+00, 2.7389e+01,\n",
      "         3.8735e+01, 5.2586e+00, 0.0000e+00, 2.8953e+01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.9549e+01, 5.8764e+01, 0.0000e+00, 1.8983e+01, 5.7198e+01,\n",
      "         1.2233e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.8095e+01, 2.0527e+01, 1.0647e+01, 0.0000e+00, 8.6034e+00,\n",
      "         0.0000e+00, 0.0000e+00, 6.6181e+01, 0.0000e+00, 6.4740e+01, 2.0076e+01,\n",
      "         3.4183e+01, 9.2942e+01, 0.0000e+00, 2.8673e+01, 0.0000e+00, 0.0000e+00]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Output after fc2: tensor([[4.5360e+01, 0.0000e+00, 5.1414e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.4541e+01, 0.0000e+00, 0.0000e+00, 8.7493e+01, 4.4555e+01, 2.3836e+00,\n",
      "         2.2882e+01, 0.0000e+00, 5.1777e+01, 5.8561e+01, 6.5851e+01, 1.8899e+01,\n",
      "         1.8898e+01, 0.0000e+00, 2.7961e+01, 0.0000e+00, 0.0000e+00, 1.2034e+01,\n",
      "         1.1530e+00, 3.5909e+01, 2.9437e+01, 1.4983e+01, 4.0515e+01, 2.1746e+01,\n",
      "         0.0000e+00, 5.2240e+01, 4.0981e+01, 1.5800e+01, 0.0000e+00, 0.0000e+00,\n",
      "         3.1764e+01, 2.1137e+01, 2.0555e+01, 2.7726e+01, 0.0000e+00, 9.9523e+00,\n",
      "         0.0000e+00, 9.6050e+00, 5.0887e+01, 4.6644e+01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.1268e+00, 0.0000e+00, 8.0392e+00, 0.0000e+00,\n",
      "         4.1806e+01, 6.5240e+01, 6.7596e-02, 0.0000e+00, 3.2859e+01, 2.0143e+01,\n",
      "         1.7893e+01, 1.9902e+01, 0.0000e+00, 4.5325e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.8875e+01, 4.6732e+00, 5.2433e+01, 3.1820e+01, 2.5733e+01, 0.0000e+00,\n",
      "         1.5045e+01, 0.0000e+00, 2.8751e+01, 3.1854e+01, 0.0000e+00, 1.3478e+01,\n",
      "         0.0000e+00, 1.6899e+01, 3.2352e+01, 0.0000e+00, 3.7507e+00, 2.7108e+01]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Final output: tensor([[ 43.8445, -65.3327, -75.7436,  -5.6119,  -6.2611,  19.7305,  34.2439,\n",
      "         -53.8421,  96.0320, -12.3039]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 43.8445, -65.3327, -75.7436,  -5.6119,  -6.2611,  19.7305,  34.2439,\n",
      "         -53.8421,  96.0320, -12.3039]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_tensor = torch.randn(1, 1, 28, 28)  # 1个样本，1个通道，28x28图像\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        input_tensor[0, 0, i, j] = i + j\n",
    "\n",
    "\n",
    "# 访问Tensor的数据\n",
    "data = input_tensor.data\n",
    "\n",
    "# 打印Tensor的数据\n",
    "print(\"Original Data:\")\n",
    "print(data)\n",
    "outputs = model(input_tensor)\n",
    "print(outputs.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14c0aa67f493870b1cfed0184ad0d403216e262e550750e2b2bf94ebe8b9137d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
